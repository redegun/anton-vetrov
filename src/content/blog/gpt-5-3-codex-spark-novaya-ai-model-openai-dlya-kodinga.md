---
title: "GPT-5.3-Codex-Spark — новая AI-модель OpenAI для кодинга"
description: "OpenAI выпустила GPT-5.3-Codex-Spark — модель для кодинга в реальном времени на железе Cerebras. Скорость свыше 1000 токенов/сек, доступна подписчикам ChatGPT Pro."
pubDate: 2026-02-27
category: "Новости ИИ"
tags: ["OpenAI", "GPT-5.3", "Codex-Spark", "AI для кодинга", "ChatGPT Pro"]
author: "Антон Ветров"
heroImage: "/images/blog/hero-gpt-5-3-codex-spark.webp"
---

OpenAI представила GPT-5.3-Codex-Spark — свою первую модель, созданную специально для кодинга в реальном времени. Релиз состоялся 27 февраля 2026 года в формате research preview и доступен подписчикам ChatGPT Pro. Модель работает на специализированном железе от Cerebras и выдаёт более 1000 токенов в секунду — это принципиально другая скорость взаимодействия с AI-ассистентом при написании кода.

## Что такое Codex-Spark и зачем он нужен

Codex-Spark — это компактная версия полноценной модели GPT-5.3-Codex, оптимизированная не столько для глубокого многочасового рассуждения, сколько для мгновенного отклика. Идея простая: у OpenAI уже есть мощные модели, которые умеют автономно работать часами и днями над сложными задачами. Но при живой работе с кодом — когда ты правишь функцию, рефакторишь логику или подстраиваешь интерфейс — нужна не глубина, а скорость. Именно эту нишу занимает Codex-Spark.

Модель заточена под интерактивную работу: ты можешь прервать её, перенаправить, уточнить задачу — и получить ответ практически мгновенно. По умолчанию она делает минимальные, точечные правки и не запускает тесты автоматически, если ты не попросишь. Это сознательный выбор: лёгкий стиль работы ради максимальной отзывчивости.

## Партнёрство с Cerebras: почему так быстро

Скорость Codex-Spark — не только заслуга самой модели. OpenAI впервые использует для инференса чипы Cerebras Wafer Scale Engine 3 — специализированный AI-ускоритель, спроектированный для сверхнизкой задержки. Это первый результат партнёрства OpenAI и Cerebras, о котором объявили в январе 2026 года.

Традиционные GPU остаются основой инфраструктуры OpenAI для обучения и массового инференса — они дают самые экономичные токены для общего использования. Cerebras дополняет эту базу там, где критична именно задержка, а не пропускная способность. При этом GPU и Cerebras можно комбинировать в рамках одной нагрузки для достижения оптимальной производительности.

Шон Ли, CTO и сооснователь Cerebras, отметил: «Больше всего нас вдохновляет возможность вместе с OpenAI и сообществом разработчиков исследовать, что открывает быстрый инференс — новые паттерны взаимодействия, новые сценарии использования и принципиально иной опыт работы с моделью».

## Технические характеристики

Вот что известно о Codex-Spark на момент запуска:

- **Контекстное окно:** 128k токенов
- **Скорость генерации:** более 1000 токенов в секунду
- **Модальность:** только текст (без изображений и других модальностей)
- **Формат:** research preview с отдельными лимитами на использование

## Сравнение с GPT-5.3-Codex

Codex-Spark — это не замена полноценной GPT-5.3-Codex, а её дополнение. Вот как они соотносятся:

**GPT-5.3-Codex (полная версия):**
- Предназначена для длительных автономных задач — может работать часами и даже неделями
- Максимальная глубина рассуждения
- Подходит для сложного рефакторинга, архитектурных решений, масштабных задач

**GPT-5.3-Codex-Spark:**
- Предназначена для интерактивной работы в реальном времени
- Упор на скорость отклика, а не на глубину
- Точечные правки, быстрая итерация
- Можно прерывать и перенаправлять на лету

На бенчмарках SWE-Bench Pro и Terminal-Bench 2.0 — двух тестах для оценки агентных способностей в программной инженерии — Codex-Spark показала сильные результаты, при этом выполняя задачи за значительно меньшее время по сравнению с полной GPT-5.3-Codex. То есть качество решения задач остаётся высоким, но время выполнения кардинально сокращается.

## Оптимизации инфраструктуры: не только модель

Интересный момент: в процессе разработки Codex-Spark в OpenAI обнаружили, что скорость самой модели — лишь часть уравнения. Для настоящего real-time взаимодействия нужно было снизить задержки по всему пайплайну запрос-ответ.

Что было сделано:

- **Переход на WebSocket-соединения.** Вместо обычных HTTP-запросов используется постоянное WebSocket-подключение, что убирает накладные расходы на установку соединения при каждом запросе.
- **Снижение overhead на каждый roundtrip клиент-сервер на 80%.** Это значит, что каждый цикл «отправил запрос — получил ответ» стал в 5 раз легче.
- **Снижение overhead на каждый токен на 30%.** Оптимизации в инференс-стеке.
- **Снижение time-to-first-token на 50%.** Первый токен ответа появляется вдвое быстрее.

Все эти улучшения реализованы в инфраструктуре Codex в целом и со временем распространятся на все модели. WebSocket-путь включён для Codex-Spark по умолчанию и скоро станет стандартом для всех моделей OpenAI.

## Что это даёт на практике

Представьте типичный рабочий процесс разработчика с AI-ассистентом. Вы пишете код, видите проблему, просите модель помочь. При задержке в несколько секунд на каждый запрос это ощущается как разговор по рации — сказал, подождал, получил ответ. При задержке в доли секунды это больше похоже на парное программирование: вы думаете вслух, а ассистент мгновенно реагирует.

Конкретные сценарии, где Codex-Spark раскрывается лучше всего:

- **Быстрые правки кода.** Переименовать переменную, исправить баг, добавить обработку ошибок — всё то, где не нужен глубокий анализ, а нужна скорость.
- **Итеративная разработка UI.** Поправить стили, перестроить layout, добавить анимацию — и сразу видеть результат.
- **Рефакторинг по частям.** Когда ты знаешь, что хочешь сделать, и нужен помощник, который быстро выполняет конкретные трансформации.
- **Код-ревью в реальном времени.** Пройтись по файлу и сразу получать комментарии и предложения.

## Планы на будущее: два режима работы

OpenAI видит будущее Codex как систему с двумя взаимодополняющими режимами:

1. **Long-horizon** — глубокое рассуждение и автономное выполнение сложных задач (текущая GPT-5.3-Codex).
2. **Real-time** — мгновенное интерактивное взаимодействие (Codex-Spark).

Со временем эти режимы будут сливаться. Например, Codex сможет вести с вами интерактивный диалог в реальном времени и одновременно делегировать более тяжёлые задачи суб-агентам в фоновом режиме. Или распределять задачи по нескольким моделям параллельно, когда нужны и широта, и скорость. Пользователю не придётся выбирать режим заранее — система сама определит оптимальный подход.

Кроме того, OpenAI обещает развивать линейку сверхбыстрых моделей: в планах более крупные модели, увеличенный контекст и мультимодальный ввод.

## Безопасность

Codex-Spark прошла стандартный процесс safety-оценки OpenAI, включая тренировку на кибербезопасность. По результатам проверки модель не достигает порога высоких возможностей в области кибербезопасности или биологии по Preparedness Framework от OpenAI. Другими словами, несмотря на скорость, модель не представляет повышенных рисков по сравнению с основными моделями компании.

## Как попробовать

На момент запуска Codex-Spark доступен в следующих форматах:

- **Codex-приложение** (последняя версия)
- **Codex CLI** (командная строка)
- **VS Code расширение**

Для доступа нужна **подписка ChatGPT Pro** (на февраль 2026 года — $200/месяц). Во время research preview у Codex-Spark отдельные лимиты на использование, которые не пересекаются со стандартными лимитами аккаунта. При высоком спросе возможны ограничения доступа или очереди.

Также OpenAI предоставляет доступ к Codex-Spark через API для ограниченного круга партнёров, чтобы понять, как разработчики хотят интегрировать модель в свои продукты. Расширение доступа к API обещают в ближайшие недели.

Если у вас нет подписки ChatGPT Pro и вы хотите попробовать Codex-Spark, подписку можно приобрести через [plati.market](https://plati.market) — там бывают варианты доступа к Pro-аккаунтам.

## Итог

GPT-5.3-Codex-Spark — это не просто «ещё одна модель». Это первая серьёзная попытка OpenAI решить проблему задержки при работе с AI-кодинг-ассистентом. Больше 1000 токенов в секунду, специализированное железо от Cerebras, оптимизированный пайплайн с WebSocket-соединениями — всё это складывается в принципиально новый опыт: AI, который не заставляет ждать.

Пока это research preview с ограниченным доступом, но направление задано чётко. Будущее AI-ассистентов для разработки — это не выбор между умным и быстрым. Это и то, и другое одновременно.

## Источник

[Introducing GPT-5.3-Codex-Spark — OpenAI](https://openai.com/index/introducing-gpt-5-3-codex-spark)