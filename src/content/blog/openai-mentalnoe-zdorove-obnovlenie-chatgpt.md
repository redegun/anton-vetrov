---
title: "OpenAI и ментальное здоровье: новые функции ChatGPT"
description: "OpenAI рассказала о работе над безопасностью ChatGPT: распознавание эмоций, родительский контроль и судебные разбирательства о влиянии ИИ на психику."
pubDate: 2026-03-01
category: "Новости ИИ"
tags: ["OpenAI", "ChatGPT", "ментальное здоровье", "безопасность ИИ", "родительский контроль"]
author: "Антон Ветров"
heroImage: "/images/blog/hero-ai-news-default.webp"
---

В конце февраля 2026 года OpenAI опубликовала обновление о своей работе в области ментального здоровья пользователей ChatGPT. Компания рассказала о новых функциях безопасности, улучшениях в распознавании эмоционального состояния пользователей и судебных разбирательствах, связанных с влиянием ИИ на психическое здоровье людей. Учитывая, что ChatGPT еженедельно используют более 900 миллионов человек, вопрос ответственности разработчиков становится всё острее.

## Родительский контроль: первые результаты

Ещё в сентябре 2025 года OpenAI запустила систему родительского контроля для ChatGPT. Спустя полгода компания отчитывается: семьи активно пользуются этими инструментами. Родители подростков получают уведомления о безопасности, связанные с тем, как их дети взаимодействуют с чат-ботом.

Что конкретно умеет родительский контроль сейчас:

- Привязка аккаунта подростка к родительскому
- Уведомления родителям при срабатывании триггеров безопасности
- Ограничения на определённые типы контента

OpenAI обещает развивать эти функции и дальше. Судя по формулировкам, компания видит в родительском контроле не разовую функцию, а целое направление, которое будет расширяться.

## Доверенные контакты — новая функция для взрослых

Пожалуй, самое интересное в обновлении — анонс функции «доверенных контактов» (trusted contacts). Суть проста: взрослый пользователь ChatGPT сможет назначить человека, который будет получать уведомления, когда система решит, что пользователю может понадобиться поддержка.

Представьте ситуацию: человек ведёт с ChatGPT разговор, в котором проявляются признаки серьёзного эмоционального стресса. Система распознаёт это и отправляет уведомление доверенному контакту — другу, родственнику, психологу.

Функция разрабатывается совместно с двумя экспертными группами:

- **Council on Well-Being and AI** — совет по благополучию и ИИ, созданный OpenAI для консультаций по подобным вопросам
- **Global Physicians Network** — глобальная сеть врачей, помогающая настраивать медицинские аспекты работы моделей

Точная дата запуска не названа, но OpenAI говорит «скоро» и обещает делиться подробностями по мере развёртывания в ChatGPT.

## Улучшенное распознавание эмоционального стресса

OpenAI продолжает работу над тем, как модели распознают признаки эмоционального неблагополучия в разговорах. Это направление компания начала развивать ещё раньше, но сейчас появились новые методы.

Ключевое нововведение — новые методы оценки (evaluation methods), которые симулируют длительные разговоры на тему ментального здоровья. По сути, OpenAI создаёт синтетические диалоги, в которых «пользователь» демонстрирует различные уровни эмоционального стресса, и проверяет, как модель реагирует.

Зачем это нужно:

- **Выявление рисков** — модель должна замечать, когда разговор переходит опасную черту
- **Корректные ответы** — ChatGPT должен деэскалировать ситуацию, а не усугублять её
- **Направление к реальной помощи** — в критических ситуациях бот должен рекомендовать обратиться к специалистам или на горячую линию

Это важный момент, потому что ИИ-модели по умолчанию склонны «поддерживать разговор» и подстраиваться под собеседника. В обычных ситуациях это плюс, но в контексте ментального здоровья такое поведение может быть опасным — модель рискует подкреплять деструктивные мысли вместо того, чтобы мягко перенаправить человека.

## Судебные дела: что происходит

Отдельный и весьма показательный блок обновления — информация о судебных разбирательствах. Несколько исков, связанных с влиянием ChatGPT на ментальное здоровье пользователей, были объединены в единое производство в суде Калифорнии.

Что известно:

- Суд консолидировал несколько дел в одно производство
- В ближайшее время будет назначен координирующий судья
- Адвокаты истцов заявили, что намерены подать дополнительные иски
- Новые дела, вероятно, будут включены в существующее консолидированное производство

OpenAI в своём заявлении сформулировала четыре принципа, которых придерживается в этих разбирательствах:

1. Опора на факты и добросовестные попытки разобраться в ситуации
2. Уважительное представление своей позиции с учётом сложности и нюансов ситуаций, затрагивающих реальных людей
3. Чувствительность к приватной информации, которая неизбежно фигурирует в подобных делах
4. Продолжение улучшения технологий вне зависимости от исхода судебных процессов

Компания призывает не делать поспешных выводов и дождаться, пока факты «надлежащим образом проявятся через судебный процесс». Формулировка дипломатичная, но за ней стоит вполне понятный посыл: первоначальные исковые заявления часто не отражают всей картины.

## Почему это важно для индустрии

Ситуация с ментальным здоровьем и ИИ — это не просто юридическая проблема OpenAI. Это фундаментальный вопрос для всей индустрии, и вот почему.

**Масштаб использования.** 900 миллионов еженедельных пользователей — это больше, чем население любой страны мира, кроме Китая и Индии. При таких масштабах даже крошечный процент проблемных взаимодействий превращается в огромные абсолютные числа.

**Эмоциональная привязка.** Люди склонны формировать эмоциональную связь с ИИ-собеседниками. Исследования показывают, что часть пользователей воспринимает ChatGPT и подобные системы как «друга» или «терапевта», хотя они для этого не предназначены. Это создаёт риски, которых не было у предыдущих технологий.

**Регуляторное давление.** Судебные иски — это лишь верхушка айсберга. За ними стоит растущее давление регуляторов по всему миру. Как компании будут справляться с этими кейсами, определит будущие нормы для всей индустрии.

**Прецедент ответственности.** Если суды установят, что разработчики ИИ несут ответственность за последствия разговоров с их моделями, это изменит правила игры для всех — от Google с Gemini до Anthropic с Claude и Meta с Llama.

## Что делают конкуренты

Стоит отметить, что OpenAI не единственная компания, работающая в этом направлении. Google встраивает аналогичные защитные механизмы в Gemini, Anthropic уделяет большое внимание безопасности Claude. Однако именно OpenAI, как компания с наибольшей пользовательской базой и наиболее громкими судебными делами, задаёт тон для остальных.

Характерно, что OpenAI выбрала стратегию проактивной коммуникации: не ждёт, пока суды или регуляторы заставят действовать, а публично рассказывает о своих шагах. Это разумный подход — и с точки зрения PR, и с точки зрения реальной безопасности.

## Как попробовать

Родительский контроль уже доступен в ChatGPT. Чтобы его настроить:

1. Откройте настройки ChatGPT
2. Найдите раздел управления семейным доступом (Family)
3. Привяжите аккаунт подростка к своему

Функция доверенных контактов пока не запущена — OpenAI обещает анонсировать её в ближайшее время.

Улучшенное распознавание эмоционального стресса работает «под капотом» — пользователям не нужно ничего настраивать. Модель автоматически деэскалирует разговоры и предлагает обратиться за помощью, если замечает тревожные сигналы.

Если вы пользуетесь ChatGPT активно и хотите максимум возможностей (GPT-4o, расширенные голосовые режимы, приоритетный доступ к новым функциям), подписку ChatGPT Plus можно приобрести через [plati.market](https://plati.market) — это удобный вариант оплаты, если стандартные способы недоступны.

## Что дальше

OpenAI обещает в ближайшие недели поделиться подробностями о новых методах оценки безопасности в контексте ментального здоровья. Также ожидается запуск функции доверенных контактов и назначение координирующего судьи по консолидированному делу в Калифорнии.

Ситуация развивается, и каждый шаг OpenAI в этом направлении будет внимательно отслеживаться — и конкурентами, и регуляторами, и обществом. Баланс между полезностью ИИ-ассистентов и безопасностью их пользователей остаётся одной из ключевых задач индустрии на 2026 год.

## Источник

[An update on our mental health-related work](https://openai.com/index/update-on-mental-health-related-work) — блог OpenAI